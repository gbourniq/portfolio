# Docker prune

- name: Stop running containers
  shell: docker stop $(docker ps -a -q) 2>/dev/null
  register: cmdln
  failed_when: "cmdln.rc == 2"

- name: Remove all stopped containers
  shell: docker rm $(docker ps -a -q) 2>/dev/null
  register: cmdln
  failed_when: "cmdln.rc == 2"

- name: Docker prune all
  shell: docker system prune -a -f

- name: Remove volumes
  shell: docker volume rm $(docker volume ls -q) 2>/dev/null
  register: cmdln
  failed_when: "cmdln.rc == 2"
  tags:
    - remove-volume
  
# Clean up repository root dir
- name: Deleting repo folder if exists
  become: yes
  file:
    path: "{{ PORTFOLIO_ROOT_DIR }}/"
    state: absent

# Download docker compose files as tarball
- name: Download compose files from AWS S3
  become: yes
  aws_s3:
    bucket: "{{ AWS_STORAGE_BUCKET_NAME }}"
    object: "/{{ DOCKER_DEPLOY_FOLDER }}/{{ S3_DOCKER_DEPLOY_TARBALL_CD_PIPELINE }}.tar.gz"
    dest: /tmp/{{ S3_DOCKER_DEPLOY_TARBALL_CD_PIPELINE }}.tar.gz
    mode: get
    aws_access_key: '{{AWS_ACCESS_KEY_ID}}'
    aws_secret_key: '{{AWS_SECRET_ACCESS_KEY}}'
    region: '{{AWS_REGION}}'

# Untar files and set up project root directory
- name: Untar docker deploy tarball
  become: yes
  unarchive:
    src: /tmp/{{ S3_DOCKER_DEPLOY_TARBALL_CD_PIPELINE }}.tar.gz
    dest: /home/ec2-user/
    remote_src: yes

- name: Rename root directory
  command: mv /home/ec2-user/{{ S3_DOCKER_DEPLOY_TARBALL_CD_PIPELINE}}/ {{ PORTFOLIO_ROOT_DIR }}/

- name: Recursively change ownership of root directory
  file:
    path: "{{ PORTFOLIO_ROOT_DIR }}/"
    state: directory
    recurse: yes
    owner: ec2-user
    group: ec2-user

- name: Delete temporary tarball file
  become: yes
  file:
    path: /tmp/{{ S3_DOCKER_DEPLOY_TARBALL_CD_PIPELINE }}.tar.gz
    state: absent

- name: Create certs/ directory if not exists
  become: yes
  file:
    path: "{{ PORTFOLIO_ROOT_DIR }}/deployment/docker-deployment/nginx/certs"
    state: directory
    recurse: yes
    owner: ec2-user
    group: ec2-user
    
- name: Download SSL CA signed certificate from S3
  become: yes
  aws_s3:
    bucket: "{{ AWS_STORAGE_BUCKET_NAME }}"
    object: "{{ SSL_CERT_S3_OBJECT_PATH }}"
    dest: "{{ SSL_CERT_HOST_PATH }}"
    mode: get
    aws_access_key: '{{AWS_ACCESS_KEY_ID}}'
    aws_secret_key: '{{AWS_SECRET_ACCESS_KEY}}'
    region: '{{AWS_REGION}}'

- name: Download SSL private key from AWS S3
  become: yes
  aws_s3:
    bucket: "{{ AWS_STORAGE_BUCKET_NAME }}"
    object: "{{ SSL_KEY_S3_OBJECT_PATH }}"
    dest: "{{ SSL_KEY_HOST_PATH }}"
    mode: get
    aws_access_key: '{{AWS_ACCESS_KEY_ID}}'
    aws_secret_key: '{{AWS_SECRET_ACCESS_KEY}}'
    region: '{{AWS_REGION}}'
